import sqlite3  # fallback Ù„Ùˆ Ø¹Ø§ÙŠØ² SQLite Ù„Ø§Ø­Ù‚Ù‹Ø§
from datetime import date
import csv
import psycopg
from sentence_transformers import SentenceTransformer
import json
import numpy as np
import re
import logging

# -------------------------------
# Logging Setup
# -------------------------------
logging.basicConfig(level=logging.INFO)

# -------------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# -------------------------------
DB_PATH = "bariatric_meds.db"  # fallback Ù„Ù€ SQLite Ù„Ùˆ Ø¹Ø§ÙŠØ²

POSTGRES_URL = "postgresql://postgres:12345@localhost:5432/postgres"  # ØºÙŠÙ‘Ø± Ø§Ù„Ø¨Ø§Ø³ÙˆØ±Ø¯ Ù„Ùˆ Ù…Ø®ØªÙ„Ù

SCHEMA_POSTGRES = """
CREATE TABLE IF NOT EXISTS meds (
    id SERIAL PRIMARY KEY,
    drug_name TEXT UNIQUE,
    generic_name TEXT,
    drug_class TEXT,
    indication TEXT,
    status_after_sleeve TEXT,
    reason TEXT,
    dose_adjustment_notes TEXT,
    administration_form TEXT,
    interactions TEXT,
    evidence_level TEXT,
    source_links TEXT,
    last_reviewed DATE,
    notes TEXT,
    embedding JSONB
);
"""

EXAMPLE_ENTRIES = [
    {
        "drug_name": "Ibuprofen",
        "generic_name": "ibuprofen",
        "drug_class": "NSAID",
        "indication": "Ù…Ø³ÙƒÙ†/Ù…Ø¶Ø§Ø¯ Ø§Ù„ØªÙ‡Ø§Ø¨",
        "status_after_sleeve": "avoid",
        "reason": "ÙŠØ²ÙŠØ¯ Ø®Ø·Ø± Ø§Ù„ØªÙ‚Ø±Ø­Ø§Øª Ø¨Ø¹Ø¯ Ø¬Ø±Ø§Ø­Ø§Øª Ø§Ù„Ø³Ù…Ù†Ø©",
        "dose_adjustment_notes": "ØªØ¬Ù†Ø¨ Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ù† Ø£Ù…ÙƒÙ†Ø› Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„ ÙƒØ¨Ø¯ÙŠÙ„",
        "administration_form": "tablet",
        "interactions": "",
        "evidence_level": "guideline/review",
        "source_links": "https://www.sps.nhs.uk/articles/considerations-for-using-medicines-following-bariatric-surgery/",
        "last_reviewed": str(date.today()),
        "notes": "Ù…Ù…Ù†ÙˆØ¹ ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙƒÙ…ÙŠÙ…."
    },
    {
        "drug_name": "Omeprazole",
        "generic_name": "omeprazole",
        "drug_class": "PPI",
        "indication": "Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø±Ø­Ø©/Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø§Ø±ØªØ¬Ø§Ø¹",
        "status_after_sleeve": "conditional",
        "reason": "ÙŠÙØ³ØªØ®Ø¯Ù… ÙƒÙˆÙ‚Ø§ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ø±Ø§Ø­Ø© Ù„ÙØªØ±Ø© Ù…Ø¹ÙŠÙ†Ø©",
        "dose_adjustment_notes": "Ø¹Ø§Ø¯Ø© ÙŠÙÙˆØµÙ Ù„Ø´Ù‡ÙˆØ± Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©",
        "administration_form": "capsule",
        "interactions": "",
        "evidence_level": "guideline",
        "source_links": "https://pubmed.ncbi.nlm.nih.gov/",
        "last_reviewed": str(date.today()),
        "notes": "Ø§Ù„Ù…Ø¯Ø© ØªØ®ØªÙ„Ù Ø­Ø³Ø¨ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¬Ø±Ù‘Ø§Ø­."
    },
    {
        "drug_name": "Paracetamol",
        "generic_name": "acetaminophen",
        "drug_class": "Analgesic",
        "indication": "Ù…Ø³ÙƒÙ† Ø£Ù„Ù…",
        "status_after_sleeve": "allowed",
        "reason": "Ø¢Ù…Ù† ÙƒÙ…Ø³ÙƒÙ† Ø¨Ø¹Ø¯ Ø§Ù„ØªÙƒÙ…ÙŠÙ…",
        "dose_adjustment_notes": "Ø§Ù†ØªØ¨Ù‡ Ù„Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ø§Ù„ÙŠÙˆÙ…ÙŠØ©",
        "administration_form": "tablet/liquid",
        "interactions": "",
        "evidence_level": "guideline",
        "source_links": "https://www.ssmhealth.com/",
        "last_reviewed": str(date.today()),
        "notes": "Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ø§Ù„Ù…ÙØ¶Ù„ Ù„Ù„Ù…Ø³ÙƒÙ†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙƒÙ…ÙŠÙ…."
    }
]

# -------------------------------
# PostgreSQL Connection
# -------------------------------
def get_connection():
    try:
        conn = psycopg.connect(POSTGRES_URL)
        logging.info("âœ… Connected to PostgreSQL.")
        return conn
    except Exception as e:
        logging.error(f"DB Connection error: {e}. ØªØ£ÙƒØ¯ Ø¥Ù† PostgreSQL Ø´ØºØ§Ù„ Ùˆ Ø§Ù„Ù€ URL ØµØ­.")
        return None

def create_postgres_table():
    conn = get_connection()
    if not conn:
        return False
    try:
        with conn.cursor() as cur:
            cur.execute(SCHEMA_POSTGRES)
        conn.commit()
        logging.info("âœ… Table 'meds' created or exists.")
        return True
    except Exception as e:
        logging.error(f"Table creation error: {e}")
        return False
    finally:
        conn.close()

# -------------------------------
# Embeddings (Ù…Ø¹Ø¯Ù„: model multilingual Ù„Ù„Ø¹Ø±Ø¨ÙŠ)
# -------------------------------
# Ø­Ù…Ù„ Ø§Ù„Ù€ model (Ø£ÙˆÙ„ Ù…Ø±Ø© Ù‡ÙŠØ§Ø®Ø¯ ÙˆÙ‚Øª)
try:
    model = SentenceTransformer("intfloat/multilingual-e5-large")
    logging.info("âœ… Multilingual embedding model loaded.")
except Exception as e:
    logging.error(f"Model load error: {e}. Ø¬Ø±Ø¨ pip install sentence-transformers")
    model = None

def get_embeddings(texts):
    if not model:
        return [[] for _ in texts]  # fallback Ù„Ùˆ Ù…Ø´ Ù…Ø­Ù…Ù„
    # Normalize: lowercase ÙˆØ¥Ø²Ø§Ù„Ø© Ø¥Ø´Ø§Ø±Ø§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù€ similarity
    normalized = [re.sub(r'[^\w\s]', '', t.lower().strip()) for t in texts]
    return model.encode(normalized, convert_to_numpy=True).tolist()

def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)

# -------------------------------
# Ø¥Ø¯Ø®Ø§Ù„ / Ø¨Ø­Ø« (Ù…Ø¹Ø¯Ù„)
# -------------------------------
def insert_drug(entry: dict):
    defaults = {
        "drug_class": "",
        "status_after_sleeve": "",
        "reason": "",
        "dose_adjustment_notes": "",
        "administration_form": "",
        "interactions": "",
        "evidence_level": "",
        "source_links": "",
        "last_reviewed": date.today(),
        "notes": ""
    }
    for k, v in defaults.items():
        entry.setdefault(k, v)

    conn = get_connection()
    try:
        with conn.cursor() as cur:
            cols = ",".join(entry.keys())
            placeholders = ",".join(["%s"] * len(entry))
            sql = f"""
                INSERT INTO meds ({cols}) VALUES ({placeholders})
                ON CONFLICT (drug_name) DO UPDATE SET
                    generic_name = EXCLUDED.generic_name,
                    indication = EXCLUDED.indication,
                    notes = EXCLUDED.notes,
                    last_reviewed = EXCLUDED.last_reviewed
                RETURNING id;
            """
            cur.execute(sql, tuple(entry.values()))
            result = cur.fetchone()

            if result:
                drug_id = result[0]
                text = f"{entry['drug_name']} ({entry.get('generic_name','')}) - {entry.get('indication','')}"
                emb = get_embeddings([text])[0]
                cur.execute(
                    "UPDATE meds SET embedding = %s WHERE id = %s;",
                    (json.dumps(emb), drug_id)
                )
                logging.info(f"âœ… Drug '{entry['drug_name']}' inserted/updated with embedding.")
            else:
                logging.warning(f"âš ï¸ Drug '{entry['drug_name']}' already exists. Updated fields.")

        # Ù…Ù‡Ù…: Ù†Ø¹Ù…Ù„ commit Ø¨Ø¹Ø¯ Ù…Ø§ Ù†Ù‚ÙÙ„ Ø§Ù„ÙƒÙŠØ±Ø³ÙˆØ±
        conn.commit()
        logging.info(f"ğŸ’¾ Drug '{entry['drug_name']}' saved to DB successfully.")
        return True

    except Exception as e:
        logging.error(f"Insert error: {e}")
        return False

    finally:
        conn.close()

def search_drug(query: str, top_k: int = 3):
    if not query.strip():
        return []

    conn = get_connection()
    if not conn:
        logging.error("Cannot search: No DB connection.")
        return []

    # 1ï¸âƒ£ Exact/Partial match fallback (SQL LIKE â€“ Ø£Ø³Ø±Ø¹ ÙˆØ£Ø¯Ù‚ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡)
    try:
        with conn.cursor() as cur:
            # Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ Ø¹Ù„Ù‰ drug_name Ø£Ùˆ generic_name (case-insensitive)
            cur.execute("""
                SELECT drug_name, generic_name, drug_class, indication,
                       status_after_sleeve, reason, dose_adjustment_notes,
                       administration_form, interactions, evidence_level,
                       source_links, notes, embedding
                FROM meds 
                WHERE LOWER(drug_name) LIKE LOWER(%s) OR LOWER(generic_name) LIKE LOWER(%s)
                LIMIT %s;
            """, (f"%{query}%", f"%{query}%", top_k))
            exact_rows = cur.fetchall()
        
        if exact_rows:
            results = []
            for row in exact_rows:
                emb = json.loads(row[12]) if row[12] else []
                results.append({
                    "drug_name": row[0], "generic_name": row[1], "drug_class": row[2],
                    "indication": row[3], "status_after_sleeve": row[4], "reason": row[5],
                    "dose_adjustment_notes": row[6], "administration_form": row[7],
                    "interactions": row[8], "evidence_level": row[9], "source_links": row[10],
                    "notes": row[11],
                })
            logging.info(f"âœ… Exact search for '{query}': {len(results)} results.")
            conn.close()
            return results
    except Exception as e:
        logging.error(f"Exact search error: {e}")

    # 2ï¸âƒ£ Semantic search (Ù„Ùˆ Ù…ÙÙŠØ´ exact)
    try:
        query_emb = get_embeddings([query])[0]
        with conn.cursor() as cur:
            cur.execute("""
                SELECT drug_name, generic_name, drug_class, indication,
                       status_after_sleeve, reason, dose_adjustment_notes,
                       administration_form, interactions, evidence_level,
                       source_links, notes, embedding
                FROM meds WHERE embedding IS NOT NULL;
            """)
            rows = cur.fetchall()

        scored = []
        for row in rows:
            emb_str = row[12]
            if isinstance(emb_str, str):
                emb = json.loads(emb_str)
            else:
                emb = emb_str or []

            if len(emb) > 0:  # ØªØ¬Ø§Ù‡Ù„ Ù„Ùˆ embedding ÙØ§Ø¶ÙŠ
                score = cosine_similarity(query_emb, emb)
                if score > 0.3:  # threshold Ù„Ù†ØªØ§Ø¦Ø¬ Ø°Ø§Øª ØµÙ„Ø© (Ø¹Ø¯Ù‘Ù„ Ù„Ùˆ Ø¹Ø§ÙŠØ² Ø£ÙˆØ³Ø¹)
                    scored.append((score, {
                        "drug_name": row[0], "generic_name": row[1], "drug_class": row[2],
                        "indication": row[3], "status_after_sleeve": row[4], "reason": row[5],
                        "dose_adjustment_notes": row[6], "administration_form": row[7],
                        "interactions": row[8], "evidence_level": row[9], "source_links": row[10],
                        "notes": row[11],
                    }))

        scored.sort(key=lambda x: x[0], reverse=True)
        results = [item for _, item in scored[:top_k]]
        logging.info(f"ğŸ” Semantic search for '{query}': {len(results)} results (top scores: {[(round(s[0], 2)) for s in scored[:3]]})")
        conn.close()
        return results
    except Exception as e:
        logging.error(f"Semantic search error: {e}")
        conn.close()
        return []

def get_all_drugs():
    conn = get_connection()
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT drug_name, generic_name, indication, notes FROM meds;")
            rows = cur.fetchall()
        # Ø­ÙˆÙ‘Ù„ Ù„Ù€ dicts Ù„Ù„ØªÙˆØ§ÙÙ‚
        results = [{"drug_name": r[0], "generic_name": r[1], "indication": r[2], "notes": r[3]} for r in rows]
        logging.info(f"ğŸ“‚ Loaded {len(results)} drugs from DB.")
        conn.close()
        return results
    except Exception as e:
        logging.error(f"Get all drugs error: {e}")
        conn.close()
        return []

# -------------------------------
# Ø¥Ø¯Ø®Ø§Ù„ ÙŠØ¯ÙˆÙŠ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù†ÙØ³ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ø¨Ø³ Ù…Ø¹ logging)
# -------------------------------
def add_drug_direct(user_input: str):
    entry = {
        "drug_name": None,
        "generic_name": None,
        "drug_class": None,
        "indication": None,
        "status_after_sleeve": None,
        "reason": None,
        "dose_adjustment_notes": None,
        "administration_form": None,
        "interactions": None,
        "evidence_level": None,
        "source_links": None,
        "last_reviewed": str(date.today()),
        "notes": None
    }

    m = re.search(r"(?:Ø§Ø³Ù…Ù‡|Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡)\s*([\w\d\+\-\s\u0600-\u06FF]+)", user_input, re.UNICODE)
    if m: entry["drug_name"] = m.group(1).strip()

    m = re.search(r"(?:Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„ÙØ¹Ø§Ù„Ø©|Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ)\s*([\w\d\+\-\s\u0600-\u06FF]+)", user_input, re.UNICODE)
    if m: entry["generic_name"] = m.group(1).strip()

    m = re.search(r"(?:Ù„Ø¹Ù„Ø§Ø¬|Ù„Ù€|ÙÙŠ)\s*([\w\d\+\-\s\u0600-\u06FF]+)", user_input, re.UNICODE)
    if m: entry["indication"] = m.group(1).strip()

    m = re.search(r"(?:Ù…Ù„Ø§Ø­Ø¸Ø§Øª|Ù…Ù„Ø§Ø­Ø¸Ø©)\s*([\w\d\+\-\s\u0600-\u06FF]+)", user_input, re.UNICODE)
    if m: entry["notes"] = m.group(1).strip()

    clean_entry = {k: v for k, v in entry.items() if v is not None}

    if not clean_entry.get("drug_name"):
        logging.warning("âš ï¸ Ù…Ø´ Ù‚Ø§Ø¯Ø± Ø£Ø³ØªØ®Ø±Ø¬ Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ.")
        return False

    success = insert_drug(clean_entry)
    if success:
        logging.info(f"âœ… {clean_entry['drug_name']} Ø§ØªØ³Ø¬Ù„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
    return success

# -------------------------------
# ØªØ´ØºÙŠÙ„ Ø±Ø¦ÙŠØ³ÙŠ (Ù…Ø¹Ø¯Ù„: Ø¨Ø¯ÙˆÙ† duplicate)
# -------------------------------
if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„
    create_postgres_table()

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù„Ùˆ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙØ§Ø¶ÙŠ
    all_drugs = get_all_drugs()
    if not all_drugs:
        logging.info("ğŸ“ Inserting example entries...")
        for e in EXAMPLE_ENTRIES:
                  insert_drug(e["drug_name"], e["generic_name"], e["indication"], e["notes"])